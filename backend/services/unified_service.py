"""
ç»Ÿä¸€æœåŠ¡å±‚ - é›†æˆå¢å¼ºå¯¹è¯ã€RAGæ£€ç´¢å’Œæ–°é—»å¡ç‰‡ç”Ÿæˆçš„å®Œæ•´è§£å†³æ–¹æ¡ˆ
"""

import asyncio
import time
import uuid
from datetime import datetime
from typing import Dict, List, Optional, Any, Union
from loguru import logger
from pydantic import BaseModel, Field

from services.enhanced_chat_service import (
    EnhancedChatService, EnhancedChatRequest, EnhancedChatResponse,
    enhanced_chat_service
)
from services.integrated_rag_service import IntegratedRAGService
from services.conversation_context_manager import context_manager
from models.news_card import NewsCardResponse
from models.chat import MessageType


class UnifiedServiceRequest(BaseModel):
    """ç»Ÿä¸€æœåŠ¡è¯·æ±‚"""
    user_id: str = Field(..., description="ç”¨æˆ·ID")
    session_id: str = Field(..., description="ä¼šè¯ID")
    query: str = Field(..., description="ç”¨æˆ·æŸ¥è¯¢")
    
    # æœåŠ¡é€‰é¡¹
    enable_enhanced_chat: bool = Field(default=True, description="å¯ç”¨å¢å¼ºå¯¹è¯")
    enable_news_card: bool = Field(default=False, description="å¯ç”¨æ–°é—»å¡ç‰‡ç”Ÿæˆ")
    enable_memory: bool = Field(default=True, description="å¯ç”¨ç”¨æˆ·è®°å¿†")
    enable_rag: bool = Field(default=True, description="å¯ç”¨RAGæ£€ç´¢")
    
    # ä¸ªæ€§åŒ–é€‰é¡¹
    response_style: Optional[str] = Field(None, description="å›å¤é£æ ¼")
    card_generation_priority: str = Field(default="quality", description="å¡ç‰‡ç”Ÿæˆä¼˜å…ˆçº§")
    
    # é«˜çº§é€‰é¡¹
    max_news_results: int = Field(default=3, description="æœ€å¤§æ–°é—»æ£€ç´¢æ•°", ge=1, le=10)
    context_depth: str = Field(default="medium", description="ä¸Šä¸‹æ–‡æ·±åº¦")


class UnifiedServiceResponse(BaseModel):
    """ç»Ÿä¸€æœåŠ¡å“åº”"""
    request_id: str = Field(..., description="è¯·æ±‚ID")
    user_id: str = Field(..., description="ç”¨æˆ·ID")
    session_id: str = Field(..., description="ä¼šè¯ID")
    
    # ä¸»è¦å“åº”å†…å®¹
    ai_response: str = Field(..., description="AIæ™ºèƒ½å›å¤")
    response_type: MessageType = Field(default=MessageType.TEXT, description="å›å¤ç±»å‹")
    
    # å¯é€‰çš„æ–°é—»å¡ç‰‡
    news_card: Optional[Any] = Field(None, description="ç”Ÿæˆçš„æ–°é—»å¡ç‰‡")
    
    # ä¸Šä¸‹æ–‡å’Œä¸ªæ€§åŒ–ä¿¡æ¯
    personalization_applied: bool = Field(default=False, description="æ˜¯å¦åº”ç”¨äº†ä¸ªæ€§åŒ–")
    context_summary: str = Field(..., description="ä¸Šä¸‹æ–‡æ‘˜è¦")
    used_features: List[str] = Field(..., description="ä½¿ç”¨çš„åŠŸèƒ½åˆ—è¡¨")
    
    # ç›¸å…³ä¿¡æ¯
    related_news: List[Dict[str, Any]] = Field(default_factory=list, description="ç›¸å…³æ–°é—»")
    suggested_topics: List[str] = Field(default_factory=list, description="æ¨èè¯é¢˜")
    memory_insights: List[str] = Field(default_factory=list, description="è®°å¿†æ´å¯Ÿ")
    
    # æ€§èƒ½æŒ‡æ ‡
    total_processing_time_ms: float = Field(..., description="æ€»å¤„ç†æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰")
    feature_timings: Dict[str, float] = Field(..., description="å„åŠŸèƒ½è€—æ—¶")
    confidence_score: float = Field(default=0.8, description="æ•´ä½“ç½®ä¿¡åº¦")
    
    # è´¨é‡æŒ‡æ ‡
    response_quality_score: float = Field(default=0.8, description="å›å¤è´¨é‡åˆ†æ•°")
    context_relevance_score: float = Field(default=0.8, description="ä¸Šä¸‹æ–‡ç›¸å…³æ€§åˆ†æ•°")


class UnifiedService:
    """ç»Ÿä¸€æœåŠ¡ - é›†æˆæ‰€æœ‰RAGå’Œå¯¹è¯åŠŸèƒ½"""
    
    def __init__(self):
        self.enhanced_chat_service = enhanced_chat_service
        self.rag_service = IntegratedRAGService()
        self.context_manager = context_manager
        
        # æ€§èƒ½ç›‘æ§
        self.request_count = 0
        self.total_processing_time = 0.0
        
        logger.info("ç»Ÿä¸€æœåŠ¡å·²åˆå§‹åŒ–")
    
    async def initialize(self):
        """åˆå§‹åŒ–æ‰€æœ‰æœåŠ¡ç»„ä»¶"""
        try:
            logger.info("ğŸš€ å¼€å§‹åˆå§‹åŒ–ç»Ÿä¸€æœåŠ¡...")
            
            # åˆå§‹åŒ–å¢å¼ºå¯¹è¯æœåŠ¡
            await self.enhanced_chat_service.initialize()
            
            # åˆå§‹åŒ–RAGæœåŠ¡
            await self.rag_service.initialize_pipeline()
            
            logger.info("âœ… ç»Ÿä¸€æœåŠ¡åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"ç»Ÿä¸€æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    async def process_unified_request(
        self, 
        request: UnifiedServiceRequest
    ) -> UnifiedServiceResponse:
        """å¤„ç†ç»Ÿä¸€æœåŠ¡è¯·æ±‚"""
        request_id = str(uuid.uuid4())
        start_time = time.time()
        feature_timings = {}
        used_features = []
        
        try:
            logger.info(f"ğŸ¯ å¤„ç†ç»Ÿä¸€è¯·æ±‚ {request_id}: {request.query[:50]}...")
            
            # 1. å¢å¼ºå¯¹è¯å¤„ç† (æ ¸å¿ƒåŠŸèƒ½)
            ai_response = ""
            personalization_applied = False
            context_summary = ""
            suggested_topics = []
            memory_insights = []
            
            if request.enable_enhanced_chat:
                chat_start = time.time()
                
                chat_request = EnhancedChatRequest(
                    user_id=request.user_id,
                    session_id=request.session_id,
                    message=request.query,
                    include_memory=request.enable_memory,
                    include_rag=request.enable_rag,
                    include_news_card=False,  # æ–°é—»å¡ç‰‡å•ç‹¬å¤„ç†
                    response_style=request.response_style,
                    max_context_memories=self._get_max_memories_by_depth(request.context_depth)
                )
                
                chat_response = await self.enhanced_chat_service.chat_with_enhanced_context(chat_request)
                
                ai_response = chat_response.response
                personalization_applied = chat_response.personalization_applied
                context_summary = chat_response.context_summary
                suggested_topics = chat_response.suggested_topics
                
                feature_timings["enhanced_chat"] = (time.time() - chat_start) * 1000
                used_features.append("å¢å¼ºå¯¹è¯")
                
                # æå–è®°å¿†æ´å¯Ÿ
                if chat_response.used_memories_count > 0:
                    memory_insights.append(f"ä½¿ç”¨äº† {chat_response.used_memories_count} æ¡å†å²è®°å¿†")
                    used_features.append("ç”¨æˆ·è®°å¿†")
            
            # 2. æ–°é—»å¡ç‰‡ç”Ÿæˆ (å¯é€‰)
            news_card = None
            if request.enable_news_card:
                card_start = time.time()
                
                try:
                    # ä½¿ç”¨å®Œæ•´çš„RAGå¢å¼ºå¡ç‰‡ç”Ÿæˆ
                    news_card = await self.rag_service.generate_news_card(request.query)
                    
                    if news_card:
                        used_features.append("æ–°é—»å¡ç‰‡ç”Ÿæˆ")
                    
                except Exception as e:
                    logger.warning(f"æ–°é—»å¡ç‰‡ç”Ÿæˆå¤±è´¥: {e}")
                
                feature_timings["news_card"] = (time.time() - card_start) * 1000
            
            # 3. ç›¸å…³æ–°é—»æ£€ç´¢ (å¢å¼ºä¿¡æ¯)
            related_news = []
            if request.enable_rag:
                rag_start = time.time()
                
                try:
                    raw_news = await self.rag_service.search_relevant_news(
                        query=request.query, 
                        top_k=request.max_news_results
                    )
                    
                    related_news = [
                        {
                            "title": news.get("title", ""),
                            "source": news.get("source", ""),
                            "category": news.get("category", ""),
                            "similarity": round(news.get("similarity", 0.0), 3),
                            "summary": news.get("content", "")[:150] + "..." if news.get("content") else ""
                        }
                        for news in raw_news
                    ]
                    
                    if related_news:
                        used_features.append("RAGæ–°é—»æ£€ç´¢")
                    
                except Exception as e:
                    logger.warning(f"ç›¸å…³æ–°é—»æ£€ç´¢å¤±è´¥: {e}")
                
                feature_timings["rag_search"] = (time.time() - rag_start) * 1000
            
            # 4. åå¤„ç†å’Œè´¨é‡è¯„ä¼°
            post_start = time.time()
            
            # è®¡ç®—è´¨é‡åˆ†æ•°
            response_quality_score = self._calculate_response_quality(
                response=ai_response,
                has_news_context=len(related_news) > 0,
                personalized=personalization_applied,
                memory_used=request.enable_memory
            )
            
            # è®¡ç®—ä¸Šä¸‹æ–‡ç›¸å…³æ€§
            context_relevance_score = self._calculate_context_relevance(
                query=request.query,
                response=ai_response,
                related_news=related_news
            )
            
            # æ›´æ–°ä¸Šä¸‹æ–‡æ‘˜è¦
            if not context_summary:
                context_summary = self._generate_unified_context_summary(
                    used_features=used_features,
                    news_count=len(related_news),
                    personalized=personalization_applied
                )
            
            feature_timings["post_processing"] = (time.time() - post_start) * 1000
            
            # 5. æ„å»ºç»Ÿä¸€å“åº”
            total_time = (time.time() - start_time) * 1000
            
            response = UnifiedServiceResponse(
                request_id=request_id,
                user_id=request.user_id,
                session_id=request.session_id,
                ai_response=ai_response,
                news_card=news_card,
                personalization_applied=personalization_applied,
                context_summary=context_summary,
                used_features=used_features,
                related_news=related_news,
                suggested_topics=suggested_topics,
                memory_insights=memory_insights,
                total_processing_time_ms=total_time,
                feature_timings=feature_timings,
                response_quality_score=response_quality_score,
                context_relevance_score=context_relevance_score
            )
            
            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self.request_count += 1
            self.total_processing_time += total_time
            
            logger.info(f"âœ… ç»Ÿä¸€è¯·æ±‚å¤„ç†å®Œæˆ {request_id}, è€—æ—¶: {total_time:.2f}ms, åŠŸèƒ½: {', '.join(used_features)}")
            
            return response
            
        except Exception as e:
            logger.error(f"ç»Ÿä¸€è¯·æ±‚å¤„ç†å¤±è´¥ {request_id}: {e}")
            raise
    
    def _get_max_memories_by_depth(self, depth: str) -> int:
        """æ ¹æ®ä¸Šä¸‹æ–‡æ·±åº¦è·å–æœ€å¤§è®°å¿†æ•°"""
        depth_mapping = {
            "shallow": 2,
            "medium": 5,
            "deep": 10
        }
        return depth_mapping.get(depth, 5)
    
    def _calculate_response_quality(
        self, 
        response: str, 
        has_news_context: bool, 
        personalized: bool, 
        memory_used: bool
    ) -> float:
        """è®¡ç®—å›å¤è´¨é‡åˆ†æ•°"""
        base_score = 0.6
        
        # é•¿åº¦è´¨é‡
        if len(response) > 100:
            base_score += 0.1
        if len(response) > 300:
            base_score += 0.1
        
        # ä¸Šä¸‹æ–‡ä¸°å¯Œåº¦
        if has_news_context:
            base_score += 0.1
        
        # ä¸ªæ€§åŒ–ç¨‹åº¦
        if personalized:
            base_score += 0.1
        
        # è®°å¿†ä½¿ç”¨
        if memory_used:
            base_score += 0.1
        
        return min(base_score, 1.0)
    
    def _calculate_context_relevance(
        self, 
        query: str, 
        response: str, 
        related_news: List[Dict]
    ) -> float:
        """è®¡ç®—ä¸Šä¸‹æ–‡ç›¸å…³æ€§åˆ†æ•°"""
        base_score = 0.5
        
        # æŸ¥è¯¢å…³é”®è¯åœ¨å›å¤ä¸­çš„å‡ºç°
        query_words = set(query.lower().split())
        response_words = set(response.lower().split())
        
        keyword_overlap = len(query_words & response_words) / max(len(query_words), 1)
        base_score += keyword_overlap * 0.3
        
        # æ–°é—»ç›¸å…³æ€§
        if related_news:
            base_score += 0.2
        
        return min(base_score, 1.0)
    
    def _generate_unified_context_summary(
        self, 
        used_features: List[str], 
        news_count: int, 
        personalized: bool
    ) -> str:
        """ç”Ÿæˆç»Ÿä¸€çš„ä¸Šä¸‹æ–‡æ‘˜è¦"""
        summary_parts = []
        
        if used_features:
            summary_parts.append(f"ä½¿ç”¨åŠŸèƒ½: {', '.join(used_features)}")
        
        if news_count > 0:
            summary_parts.append(f"æ£€ç´¢åˆ° {news_count} æ¡ç›¸å…³æ–°é—»")
        
        if personalized:
            summary_parts.append("åº”ç”¨ä¸ªæ€§åŒ–é…ç½®")
        
        return "; ".join(summary_parts) if summary_parts else "åŸºç¡€å¤„ç†æ¨¡å¼"
    
    async def get_service_status(self) -> Dict[str, Any]:
        """è·å–æœåŠ¡çŠ¶æ€"""
        avg_processing_time = (
            self.total_processing_time / self.request_count 
            if self.request_count > 0 else 0
        )
        
        return {
            "service_name": "ç»Ÿä¸€RAGæœåŠ¡",
            "status": "active",
            "request_count": self.request_count,
            "average_processing_time_ms": round(avg_processing_time, 2),
            "features": [
                "å¢å¼ºå¯¹è¯",
                "RAGæ£€ç´¢", 
                "æ–°é—»å¡ç‰‡ç”Ÿæˆ",
                "ç”¨æˆ·è®°å¿†",
                "ä¸ªæ€§åŒ–å›å¤"
            ],
            "initialized_at": datetime.utcnow().isoformat()
        }
    
    async def clear_user_data(self, user_id: str):
        """æ¸…ç†ç”¨æˆ·æ•°æ®"""
        try:
            # æ¸…ç†ç”¨æˆ·è®°å¿†
            if user_id in self.context_manager.user_profiles:
                del self.context_manager.user_profiles[user_id]
            
            # æ¸…ç†å¯¹è¯å†å²
            sessions_to_clear = []
            for session_id, messages in self.enhanced_chat_service.conversation_history.items():
                if messages and messages[0].metadata.get("user_id") == user_id:
                    sessions_to_clear.append(session_id)
            
            for session_id in sessions_to_clear:
                await self.enhanced_chat_service.clear_conversation_history(session_id)
            
            logger.info(f"å·²æ¸…ç†ç”¨æˆ· {user_id} çš„æ‰€æœ‰æ•°æ®")
            
        except Exception as e:
            logger.error(f"æ¸…ç†ç”¨æˆ·æ•°æ®å¤±è´¥: {e}")


# åˆ›å»ºå…¨å±€å®ä¾‹
unified_service = UnifiedService() 