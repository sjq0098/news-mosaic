"""
ç®€åŒ–çš„RAGå¯¹è¯æœåŠ¡ - ç»•è¿‡å¤æ‚çš„æ•°æ®éªŒè¯ï¼Œç›´æ¥è¿›è¡Œæ™ºèƒ½å¯¹è¯
"""

import asyncio
import time
from typing import List, Dict, Any, Optional
from loguru import logger

from services.qwen_service import QWENService
from services.embedding_service import QWenEmbeddingService
from mock_data.news_samples import mock_news_db


class SimpleRAGChatService:
    """ç®€åŒ–çš„RAGå¯¹è¯æœåŠ¡ - ä¸“æ³¨äºæ ¸å¿ƒåŠŸèƒ½"""
    
    def __init__(self):
        self.qwen_service = QWENService()
        self.embedding_service = QWenEmbeddingService()
        
        # æ¨¡æ‹Ÿå‘é‡å­˜å‚¨
        self.vector_store = {}
        self.news_embeddings = {}
        
        logger.info("ç®€åŒ–RAGå¯¹è¯æœåŠ¡å·²åˆå§‹åŒ–")
    
    async def initialize_pipeline(self):
        """åˆå§‹åŒ–æµæ°´çº¿ - ä¸ºæ‰€æœ‰æ–°é—»ç”Ÿæˆembedding"""
        logger.info("ğŸš€ å¼€å§‹åˆå§‹åŒ–ç®€åŒ–RAGæµæ°´çº¿...")
        
        all_news = mock_news_db.get_all_news()
        logger.info(f"ğŸ“° åŠ è½½äº† {len(all_news)} æ¡æ¨¡æ‹Ÿæ–°é—»")
        
        for i, news_data in enumerate(all_news):
            await self._process_news_embedding(news_data)
            logger.info(f"âœ… å¤„ç†æ–°é—» {i+1}/{len(all_news)}: {news_data['title'][:50]}...")
        
        logger.info(f"ğŸ¯ ç®€åŒ–RAGæµæ°´çº¿åˆå§‹åŒ–å®Œæˆï¼å…±å¤„ç† {len(all_news)} æ¡æ–°é—»")
    
    async def _process_news_embedding(self, news_data: Dict[str, Any]):
        """ä¸ºå•æ¡æ–°é—»ç”Ÿæˆembedding"""
        news_id = news_data["id"]
        
        # ç»„åˆæ–‡æœ¬ï¼šæ ‡é¢˜ + å†…å®¹æ‘˜è¦
        combined_text = f"{news_data['title']}\n\n{news_data['content'][:500]}..."
        
        try:
            # ç”Ÿæˆembedding
            embedding = await self.embedding_service.generate_embedding(combined_text)
            
            # å­˜å‚¨embeddingå’Œå…ƒæ•°æ®
            self.news_embeddings[news_id] = {
                "embedding": embedding,
                "text": combined_text,
                "news_data": news_data
            }
            
        except Exception as e:
            logger.error(f"ä¸ºæ–°é—» {news_id} ç”Ÿæˆembeddingå¤±è´¥: {e}")
    
    async def search_relevant_news(
        self, 
        query: str, 
        top_k: int = 3
    ) -> List[Dict[str, Any]]:
        """åŸºäºæŸ¥è¯¢æ£€ç´¢ç›¸å…³æ–°é—»"""
        try:
            # ä¸ºæŸ¥è¯¢ç”Ÿæˆembedding
            query_embedding = await self.embedding_service.generate_embedding(query)
            
            # è®¡ç®—ç›¸ä¼¼åº¦
            similarities = []
            
            for news_id, stored_data in self.news_embeddings.items():
                similarity = self._cosine_similarity(
                    query_embedding, 
                    stored_data["embedding"]
                )
                
                similarities.append({
                    "news_id": news_id,
                    "similarity": similarity,
                    "news_data": stored_data["news_data"]
                })
            
            # æŒ‰ç›¸ä¼¼åº¦æ’åºå¹¶è¿”å›top_k
            similarities.sort(key=lambda x: x["similarity"], reverse=True)
            
            relevant_news = []
            for item in similarities[:top_k]:
                relevant_news.append({
                    "news_data": item["news_data"],
                    "similarity_score": item["similarity"]
                })
            
            logger.info(f"ğŸ” æ£€ç´¢åˆ° {len(relevant_news)} æ¡ç›¸å…³æ–°é—»")
            return relevant_news
            
        except Exception as e:
            logger.error(f"æ£€ç´¢ç›¸å…³æ–°é—»å¤±è´¥: {e}")
            return []
    
    def _cosine_similarity(self, vec1: List[float], vec2: List[float]) -> float:
        """è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦"""
        try:
            import numpy as np
            
            vec1 = np.array(vec1)
            vec2 = np.array(vec2)
            
            dot_product = np.dot(vec1, vec2)
            norm_vec1 = np.linalg.norm(vec1)
            norm_vec2 = np.linalg.norm(vec2)
            
            if norm_vec1 == 0 or norm_vec2 == 0:
                return 0.0
            
            return dot_product / (norm_vec1 * norm_vec2)
            
        except Exception as e:
            logger.error(f"è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦å¤±è´¥: {e}")
            return 0.0
    
    async def chat_with_news_context(
        self, 
        user_query: str,
        max_context_news: int = 3
    ) -> Dict[str, Any]:
        """åŸºäºæ–°é—»ä¸Šä¸‹æ–‡è¿›è¡Œå¯¹è¯"""
        try:
            start_time = time.time()
            
            # 1. æ£€ç´¢ç›¸å…³æ–°é—»
            relevant_news = await self.search_relevant_news(user_query, top_k=max_context_news)
            
            if not relevant_news:
                logger.warning("æœªæ‰¾åˆ°ç›¸å…³æ–°é—»ï¼Œä½¿ç”¨é€šç”¨å›å¤")
                return {
                    "user_query": user_query,
                    "ai_response": "æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰æ‰¾åˆ°ä¸æ‚¨é—®é¢˜ç›¸å…³çš„æ–°é—»ä¿¡æ¯ã€‚",
                    "relevant_news": [],
                    "processing_time": time.time() - start_time
                }
            
            # 2. æ„å»ºæ–°é—»ä¸Šä¸‹æ–‡
            news_context = self._build_news_context(relevant_news)
            
            # 3. æ„å»ºå®Œæ•´æç¤º
            full_prompt = self._build_chat_prompt(user_query, news_context)
            
            # 4. è°ƒç”¨QWENç”Ÿæˆå›å¤
            response = await self.qwen_service.generate_response(
                user_message=full_prompt,
                chat_history=[],
                include_news=False,
                temperature=0.7,
                max_tokens=800
            )
            
            # 5. ç»„ç»‡è¿”å›ç»“æœ
            result = {
                "user_query": user_query,
                "ai_response": response.content,
                "relevant_news": [
                    {
                        "title": news["news_data"]["title"],
                        "source": news["news_data"]["source"],
                        "similarity": news["similarity_score"],
                        "category": news["news_data"]["category"],
                        "url": news["news_data"]["url"]
                    }
                    for news in relevant_news
                ],
                "tokens_used": response.tokens_used,
                "generation_time": response.generation_time,
                "processing_time": time.time() - start_time
            }
            
            logger.info(f"ğŸ’¬ å¯¹è¯å®Œæˆï¼Œè€—æ—¶: {result['processing_time']:.2f}ç§’")
            return result
            
        except Exception as e:
            logger.error(f"åŸºäºæ–°é—»ä¸Šä¸‹æ–‡å¯¹è¯å¤±è´¥: {e}")
            return {
                "error": str(e),
                "processing_time": time.time() - start_time
            }
    
    def _build_news_context(self, relevant_news: List[Dict[str, Any]]) -> str:
        """æ„å»ºæ–°é—»ä¸Šä¸‹æ–‡"""
        context_parts = []
        
        for i, news_item in enumerate(relevant_news, 1):
            news = news_item["news_data"]
            similarity = news_item["similarity_score"]
            
            context_part = f"""
æ–°é—» {i} (ç›¸ä¼¼åº¦: {similarity:.3f}):
æ ‡é¢˜: {news['title']}
æ¥æº: {news['source']}
åˆ†ç±»: {news['category']}
å†…å®¹æ‘˜è¦: {news['content'][:400]}...
å‘å¸ƒæ—¶é—´: {news['published_at'].strftime('%Y-%m-%d %H:%M')}
"""
            context_parts.append(context_part)
        
        return "\n".join(context_parts)
    
    def _build_chat_prompt(self, user_query: str, news_context: str) -> str:
        """æ„å»ºå¯¹è¯æç¤º"""
        return f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–°é—»åˆ†æåŠ©æ‰‹ã€‚è¯·æ ¹æ®æä¾›çš„ç›¸å…³æ–°é—»ä¿¡æ¯ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

ç›¸å…³æ–°é—»ä¿¡æ¯:
{news_context}

ç”¨æˆ·é—®é¢˜: {user_query}

è¯·æä¾›ä¸“ä¸šã€å‡†ç¡®çš„åˆ†æå›å¤ã€‚å›å¤åº”è¯¥:
1. åŸºäºæä¾›çš„æ–°é—»ä¿¡æ¯
2. ç»“æ„æ¸…æ™°ï¼Œé€»è¾‘ä¸¥è°¨
3. å®¢è§‚ä¸­æ€§ï¼Œé¿å…ä¸»è§‚æ¨æµ‹
4. å¦‚æœæ¶‰åŠå¤šæ¡æ–°é—»ï¼Œå¯ä»¥è¿›è¡Œå¯¹æ¯”åˆ†æ

å›å¤:
"""

    async def get_pipeline_status(self) -> Dict[str, Any]:
        """è·å–æµæ°´çº¿çŠ¶æ€"""
        return {
            "total_news": len(self.news_embeddings),
            "service_status": "ready",
            "categories": list(set([
                news_data["news_data"]["category"] 
                for news_data in self.news_embeddings.values()
            ]))
        }


# åˆ›å»ºå…¨å±€å®ä¾‹
simple_rag_chat = SimpleRAGChatService() 