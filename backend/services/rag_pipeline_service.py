"""
RAGæµæ°´çº¿æœåŠ¡ - å®Œæ•´çš„å‘é‡æ£€ç´¢ä¸LLMè°ƒåº¦æµç¨‹
"""

import asyncio
import time
from typing import List, Dict, Any, Optional
from loguru import logger
import json

from services.qwen_service import QWENService
from services.embedding_service import QWenEmbeddingService
from services.news_chat_service import NewsChatService
from services.rag_enhanced_card_service import RAGEnhancedCardService
from models.news import NewsModel
from models.news_card import NewsCardRequest, NewsCardResponse
from mock_data.news_samples import mock_news_db


class RAGPipelineService:
    """RAGæµæ°´çº¿æœåŠ¡ - ä»æ–°é—»æ•°æ®åˆ°æ™ºèƒ½å›å¤çš„å®Œæ•´æµç¨‹"""
    
    def __init__(self):
        self.qwen_service = QWENService()
        self.embedding_service = QWenEmbeddingService()
        self.chat_service = NewsChatService()
        self.card_service = RAGEnhancedCardService()
        
        # æ¨¡æ‹Ÿå‘é‡å­˜å‚¨ï¼ˆå®é™…åº”ç”¨ä¸­åº”è¯¥æ˜¯Pinecone/Weaviateï¼‰
        self.vector_store = {}
        self.news_embeddings = {}
        
        logger.info("RAGæµæ°´çº¿æœåŠ¡å·²åˆå§‹åŒ–")
    
    async def initialize_pipeline(self):
        """åˆå§‹åŒ–æµæ°´çº¿ - ä¸ºæ‰€æœ‰æ–°é—»ç”Ÿæˆembedding"""
        logger.info("ğŸš€ å¼€å§‹åˆå§‹åŒ–RAGæµæ°´çº¿...")
        
        # è·å–æ‰€æœ‰æ¨¡æ‹Ÿæ–°é—»æ•°æ®
        all_news = mock_news_db.get_all_news()
        logger.info(f"ğŸ“° åŠ è½½äº† {len(all_news)} æ¡æ¨¡æ‹Ÿæ–°é—»")
        
        # ä¸ºæ¯æ¡æ–°é—»ç”Ÿæˆembedding
        for i, news_data in enumerate(all_news):
            await self._process_news_embedding(news_data)
            logger.info(f"âœ… å¤„ç†æ–°é—» {i+1}/{len(all_news)}: {news_data['title'][:50]}...")
        
        logger.info(f"ğŸ¯ RAGæµæ°´çº¿åˆå§‹åŒ–å®Œæˆï¼å…±å¤„ç† {len(all_news)} æ¡æ–°é—»")
    
    async def _process_news_embedding(self, news_data: Dict[str, Any]):
        """ä¸ºå•æ¡æ–°é—»ç”Ÿæˆembedding"""
        news_id = news_data["id"]
        
        # ç»„åˆæ–‡æœ¬ï¼šæ ‡é¢˜ + å†…å®¹æ‘˜è¦
        combined_text = f"{news_data['title']}\n\n{news_data['content'][:500]}..."
        
        try:
            # ç”Ÿæˆembedding
            embedding = await self.embedding_service.generate_embedding(combined_text)
            
            # å­˜å‚¨embeddingå’Œå…ƒæ•°æ®
            self.news_embeddings[news_id] = {
                "embedding": embedding,
                "text": combined_text,
                "news_data": news_data
            }
            
            # æ¨¡æ‹Ÿå‘é‡å­˜å‚¨ï¼ˆå®é™…åº”ç”¨ä¸­ä¼šå­˜å‚¨åˆ°å‘é‡æ•°æ®åº“ï¼‰
            self.vector_store[news_id] = {
                "vector": embedding,
                "metadata": {
                    "title": news_data["title"],
                    "category": news_data["category"],
                    "published_at": news_data["published_at"].isoformat(),
                    "source": news_data["source"],
                    "tags": news_data["tags"]
                }
            }
            
        except Exception as e:
            logger.error(f"ä¸ºæ–°é—» {news_id} ç”Ÿæˆembeddingå¤±è´¥: {e}")
    
    async def search_relevant_news(
        self, 
        query: str, 
        top_k: int = 5
    ) -> List[Dict[str, Any]]:
        """åŸºäºæŸ¥è¯¢æ£€ç´¢ç›¸å…³æ–°é—»"""
        try:
            # ä¸ºæŸ¥è¯¢ç”Ÿæˆembedding
            query_embedding = await self.embedding_service.generate_embedding(query)
            
            # è®¡ç®—ç›¸ä¼¼åº¦ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œå®é™…åº”è¯¥ä½¿ç”¨å‘é‡æ•°æ®åº“çš„ç›¸ä¼¼åº¦æœç´¢ï¼‰
            similarities = []
            
            for news_id, stored_data in self.news_embeddings.items():
                # ç®€å•çš„cosineç›¸ä¼¼åº¦è®¡ç®—
                similarity = self._cosine_similarity(
                    query_embedding, 
                    stored_data["embedding"]
                )
                
                similarities.append({
                    "news_id": news_id,
                    "similarity": similarity,
                    "news_data": stored_data["news_data"]
                })
            
            # æŒ‰ç›¸ä¼¼åº¦æ’åºå¹¶è¿”å›top_k
            similarities.sort(key=lambda x: x["similarity"], reverse=True)
            
            relevant_news = []
            for item in similarities[:top_k]:
                relevant_news.append({
                    "news_data": item["news_data"],
                    "similarity_score": item["similarity"]
                })
            
            logger.info(f"ğŸ” æ£€ç´¢åˆ° {len(relevant_news)} æ¡ç›¸å…³æ–°é—»")
            return relevant_news
            
        except Exception as e:
            logger.error(f"æ£€ç´¢ç›¸å…³æ–°é—»å¤±è´¥: {e}")
            return []
    
    def _cosine_similarity(self, vec1: List[float], vec2: List[float]) -> float:
        """è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦"""
        try:
            import numpy as np
            
            vec1 = np.array(vec1)
            vec2 = np.array(vec2)
            
            dot_product = np.dot(vec1, vec2)
            norm_vec1 = np.linalg.norm(vec1)
            norm_vec2 = np.linalg.norm(vec2)
            
            if norm_vec1 == 0 or norm_vec2 == 0:
                return 0.0
            
            return dot_product / (norm_vec1 * norm_vec2)
            
        except Exception as e:
            logger.error(f"è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦å¤±è´¥: {e}")
            return 0.0
    
    async def generate_news_card(self, news_data: Dict[str, Any]) -> Optional[NewsCardResponse]:
        """ä¸ºæ–°é—»ç”Ÿæˆç»“æ„åŒ–å¡ç‰‡"""
        try:
            # è½¬æ¢ä¸ºNewsModelæ ¼å¼
            from models.news import NewsSource
            news_model = NewsModel(
                id=news_data["id"],
                title=news_data["title"],
                content=news_data["content"],
                source=NewsSource.MANUAL,  # ä½¿ç”¨MANUALä½œä¸ºé»˜è®¤æ¥æº
                url=news_data["url"],
                published_at=news_data["published_at"]
            )
            
            # åˆ›å»ºè¯·æ±‚ï¼ˆæ·»åŠ å¿…éœ€çš„news_idå­—æ®µï¼‰
            request = NewsCardRequest(
                news_id=news_data["id"],
                include_sentiment=True,
                include_entities=True,
                include_summary=True
            )
            
            # ç”Ÿæˆå¡ç‰‡
            card_response = await self.card_service.generate_card_with_rag(news_model, request)
            return card_response
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆæ–°é—»å¡ç‰‡å¤±è´¥: {e}")
            return None
    
    async def chat_with_news_context(
        self, 
        user_query: str, 
        session_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """åŸºäºæ–°é—»ä¸Šä¸‹æ–‡è¿›è¡Œå¯¹è¯"""
        try:
            start_time = time.time()
            
            # 1. æ£€ç´¢ç›¸å…³æ–°é—»
            relevant_news = await self.search_relevant_news(user_query, top_k=3)
            
            if not relevant_news:
                logger.warning("æœªæ‰¾åˆ°ç›¸å…³æ–°é—»ï¼Œä½¿ç”¨é€šç”¨å›å¤")
                return {
                    "response": "æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰æ‰¾åˆ°ä¸æ‚¨é—®é¢˜ç›¸å…³çš„æ–°é—»ä¿¡æ¯ã€‚",
                    "relevant_news": [],
                    "processing_time": time.time() - start_time
                }
            
            # 2. å¦‚æœæ²¡æœ‰ä¼šè¯ï¼Œåˆ›å»ºæ–°ä¼šè¯
            if not session_id:
                # ä½¿ç”¨ç¬¬ä¸€æ¡ç›¸å…³æ–°é—»åˆ›å»ºä¼šè¯
                first_news = relevant_news[0]["news_data"]
                from models.news import NewsSource
                news_model = NewsModel(
                    id=first_news["id"],
                    title=first_news["title"],
                    content=first_news["content"],
                    source=NewsSource.MANUAL,  # ä½¿ç”¨MANUALä½œä¸ºé»˜è®¤æ¥æº
                    url=first_news["url"],
                    published_at=first_news["published_at"]
                )
                
                # åˆ›å»ºæ–°ä¼šè¯
                session = await self.chat_service.create_news_session(
                    user_id="demo_user", 
                    initial_news=news_model,
                    session_title=f"å…³äºï¼š{news_model.title[:30]}..."
                )
                session_id = session.id
                logger.info(f"ğŸ†• åˆ›å»ºæ–°å¯¹è¯ä¼šè¯: {session_id}")
            
            # 3. å‘é€æ¶ˆæ¯å¹¶è·å–å›å¤
            chat_result = await self.chat_service.send_news_message(
                session_id, 
                user_query,
                user_id="demo_user"
            )
            
            # 4. ç»„ç»‡è¿”å›ç»“æœ
            result = {
                "session_id": session_id,
                "user_query": user_query,
                "ai_response": chat_result["assistant_message"]["content"],
                "relevant_news": [
                    {
                        "title": news["news_data"]["title"],
                        "source": news["news_data"]["source"],
                        "similarity": news["similarity_score"],
                        "url": news["news_data"]["url"]
                    }
                    for news in relevant_news
                ],
                "suggested_questions": chat_result.get("suggested_questions", []),
                "processing_time": time.time() - start_time
            }
            
            logger.info(f"ğŸ’¬ å¯¹è¯å®Œæˆï¼Œè€—æ—¶: {result['processing_time']:.2f}ç§’")
            return result
            
        except Exception as e:
            logger.error(f"åŸºäºæ–°é—»ä¸Šä¸‹æ–‡å¯¹è¯å¤±è´¥: {e}")
            return {
                "error": str(e),
                "processing_time": time.time() - start_time
            }
    
    async def get_pipeline_status(self) -> Dict[str, Any]:
        """è·å–æµæ°´çº¿çŠ¶æ€"""
        return {
            "total_news": len(self.news_embeddings),
            "vector_store_size": len(self.vector_store),
            "services_status": {
                "qwen_service": "ready",
                "embedding_service": "ready", 
                "chat_service": "ready",
                "card_service": "ready"
            },
            "categories": list(set([
                news_data["news_data"]["category"] 
                for news_data in self.news_embeddings.values()
            ]))
        }
    
    async def demo_complete_pipeline(self, query: str) -> Dict[str, Any]:
        """æ¼”ç¤ºå®Œæ•´æµæ°´çº¿çš„ç«¯åˆ°ç«¯è¿‡ç¨‹"""
        logger.info(f"ğŸ¯ å¼€å§‹æ¼”ç¤ºå®Œæ•´RAGæµæ°´çº¿: {query}")
        
        pipeline_start = time.time()
        result = {
            "query": query,
            "steps": [],
            "final_result": None,
            "total_time": 0
        }
        
        try:
            # æ­¥éª¤1: æ£€ç´¢ç›¸å…³æ–°é—»
            step1_start = time.time()
            relevant_news = await self.search_relevant_news(query, top_k=3)
            step1_time = time.time() - step1_start
            
            result["steps"].append({
                "step": "1. æ–°é—»æ£€ç´¢",
                "description": f"åŸºäºæŸ¥è¯¢æ£€ç´¢åˆ° {len(relevant_news)} æ¡ç›¸å…³æ–°é—»",
                "time": step1_time,
                "data": [news["news_data"]["title"] for news in relevant_news[:3]]
            })
            
            if not relevant_news:
                result["final_result"] = "æœªæ‰¾åˆ°ç›¸å…³æ–°é—»"
                return result
            
            # æ­¥éª¤2: ç”Ÿæˆæ–°é—»å¡ç‰‡
            step2_start = time.time()
            top_news = relevant_news[0]["news_data"]
            card_result = await self.generate_news_card(top_news)
            step2_time = time.time() - step2_start
            
            result["steps"].append({
                "step": "2. æ–°é—»å¡ç‰‡ç”Ÿæˆ",
                "description": "ä¸ºæœ€ç›¸å…³çš„æ–°é—»ç”Ÿæˆç»“æ„åŒ–å¡ç‰‡",
                "time": step2_time,
                "data": {
                    "title": card_result.news_id if card_result else "ç”Ÿæˆå¤±è´¥",
                    "status": "æˆåŠŸ" if card_result else "å¤±è´¥"
                }
            })
            
            # æ­¥éª¤3: åŸºäºä¸Šä¸‹æ–‡å¯¹è¯
            step3_start = time.time()
            chat_result = await self.chat_with_news_context(query)
            step3_time = time.time() - step3_start
            
            result["steps"].append({
                "step": "3. æ™ºèƒ½å¯¹è¯ç”Ÿæˆ",
                "description": "åŸºäºæ–°é—»ä¸Šä¸‹æ–‡ç”ŸæˆAIå›å¤",
                "time": step3_time,
                "data": {
                    "response_length": len(chat_result.get("ai_response", "")),
                    "has_suggestions": len(chat_result.get("suggested_questions", [])) > 0
                }
            })
            
            # æœ€ç»ˆç»“æœ
            result["final_result"] = {
                "ai_response": chat_result.get("ai_response", ""),
                "relevant_news_count": len(relevant_news),
                "session_id": chat_result.get("session_id"),
                "suggested_questions": chat_result.get("suggested_questions", [])
            }
            
            result["total_time"] = time.time() - pipeline_start
            
            logger.info(f"âœ… å®Œæ•´æµæ°´çº¿æ¼”ç¤ºå®Œæˆï¼Œæ€»è€—æ—¶: {result['total_time']:.2f}ç§’")
            return result
            
        except Exception as e:
            logger.error(f"æµæ°´çº¿æ¼”ç¤ºå¤±è´¥: {e}")
            result["error"] = str(e)
            result["total_time"] = time.time() - pipeline_start
            return result


# åˆ›å»ºå…¨å±€å®ä¾‹
rag_pipeline = RAGPipelineService() 