#!/usr/bin/env python3
"""
Bç«¯å®Œæ•´æµæ°´çº¿æ¼”ç¤º - å‘é‡æ£€ç´¢ & LLMè°ƒåº¦
ä»æ¨¡æ‹Ÿæ–°é—»æ•°æ®åº“åˆ°æ™ºèƒ½å›å¤çš„ç«¯åˆ°ç«¯æµ‹è¯•
"""

import asyncio
import json
import time
from datetime import datetime

from services.rag_pipeline_service import rag_pipeline
from mock_data.news_samples import mock_news_db


async def print_banner(title: str):
    """æ‰“å°æ ‡é¢˜æ¨ªå¹…"""
    print("\n" + "=" * 80)
    print(f"ğŸ¯ {title}")
    print("=" * 80)


async def print_step(step_num: int, description: str):
    """æ‰“å°æ­¥éª¤ä¿¡æ¯"""
    print(f"\nğŸ“ æ­¥éª¤ {step_num}: {description}")
    print("-" * 60)


async def demo_pipeline_initialization():
    """æ¼”ç¤ºæµæ°´çº¿åˆå§‹åŒ–è¿‡ç¨‹"""
    await print_banner("RAGæµæ°´çº¿åˆå§‹åŒ–æ¼”ç¤º")
    
    print("ğŸ“Š æ¨¡æ‹Ÿæ–°é—»æ•°æ®æ¦‚è§ˆ:")
    all_news = mock_news_db.get_all_news()
    
    categories = {}
    for news in all_news:
        category = news["category"]
        categories[category] = categories.get(category, 0) + 1
    
    print(f"ğŸ“° æ€»æ–°é—»æ•°é‡: {len(all_news)}")
    print("ğŸ“‚ æ–°é—»åˆ†ç±»åˆ†å¸ƒ:")
    for category, count in categories.items():
        print(f"   â€¢ {category}: {count} æ¡")
    
    print("\nğŸ”„ å¼€å§‹åˆå§‹åŒ–æµæ°´çº¿...")
    start_time = time.time()
    
    await rag_pipeline.initialize_pipeline()
    
    init_time = time.time() - start_time
    print(f"âœ… æµæ°´çº¿åˆå§‹åŒ–å®Œæˆï¼Œè€—æ—¶: {init_time:.2f}ç§’")
    
    # æ˜¾ç¤ºçŠ¶æ€
    status = await rag_pipeline.get_pipeline_status()
    print(f"\nğŸ“ˆ æµæ°´çº¿çŠ¶æ€:")
    print(f"   â€¢ å·²å¤„ç†æ–°é—»: {status['total_news']} æ¡")
    print(f"   â€¢ å‘é‡å­˜å‚¨å¤§å°: {status['vector_store_size']}")
    print(f"   â€¢ æ–°é—»åˆ†ç±»: {', '.join(status['categories'])}")


async def demo_news_search():
    """æ¼”ç¤ºæ–°é—»æ£€ç´¢åŠŸèƒ½"""
    await print_banner("æ–°é—»æ£€ç´¢åŠŸèƒ½æ¼”ç¤º")
    
    test_queries = [
        "AIå¤§æ¨¡å‹æŠ€æœ¯çªç ´",
        "æ–°èƒ½æºæ±½è½¦å‘å±•",
        "é‡å­è®¡ç®—ç ”ç©¶è¿›å±•",
        "5Gç½‘ç»œå»ºè®¾"
    ]
    
    for i, query in enumerate(test_queries, 1):
        await print_step(i, f"æ£€ç´¢æŸ¥è¯¢: '{query}'")
        
        start_time = time.time()
        relevant_news = await rag_pipeline.search_relevant_news(query, top_k=3)
        search_time = time.time() - start_time
        
        print(f"ğŸ” æ£€ç´¢è€—æ—¶: {search_time:.3f}ç§’")
        print(f"ğŸ“Š æ‰¾åˆ°ç›¸å…³æ–°é—»: {len(relevant_news)} æ¡")
        
        for j, news_item in enumerate(relevant_news, 1):
            news = news_item["news_data"]
            similarity = news_item["similarity_score"]
            print(f"   {j}. [{similarity:.3f}] {news['title'][:60]}...")
            print(f"      æ¥æº: {news['source']} | åˆ†ç±»: {news['category']}")
        
        if i < len(test_queries):
            print()


async def demo_complete_pipeline():
    """æ¼”ç¤ºå®Œæ•´æµæ°´çº¿ç«¯åˆ°ç«¯è¿‡ç¨‹"""
    await print_banner("å®Œæ•´RAGæµæ°´çº¿ç«¯åˆ°ç«¯æ¼”ç¤º")
    
    test_scenarios = [
        {
            "query": "æœ€è¿‘AIé¢†åŸŸæœ‰ä»€ä¹ˆé‡å¤§çªç ´ï¼Ÿè¯·è¯¦ç»†åˆ†æä¸€ä¸‹",
            "description": "AIæŠ€æœ¯çªç ´åˆ†æ"
        },
        {
            "query": "æ–°èƒ½æºæ±½è½¦çš„å¸‚åœºè¡¨ç°å¦‚ä½•ï¼Ÿæœ‰ä»€ä¹ˆå‘å±•è¶‹åŠ¿ï¼Ÿ",
            "description": "æ–°èƒ½æºæ±½è½¦å¸‚åœºåˆ†æ"
        },
        {
            "query": "é‡å­è®¡ç®—æŠ€æœ¯çš„å®ç”¨åŒ–å‰æ™¯æ€ä¹ˆæ ·ï¼Ÿ",
            "description": "é‡å­è®¡ç®—å‘å±•å‰æ™¯"
        }
    ]
    
    for i, scenario in enumerate(test_scenarios, 1):
        await print_step(i, scenario["description"])
        
        print(f"ğŸ‘¤ ç”¨æˆ·æŸ¥è¯¢: {scenario['query']}")
        print("\nğŸ¤– å¼€å§‹å¤„ç†...")
        
        # è¿è¡Œå®Œæ•´æµæ°´çº¿
        result = await rag_pipeline.demo_complete_pipeline(scenario["query"])
        
        if "error" in result:
            print(f"âŒ å¤„ç†å¤±è´¥: {result['error']}")
            continue
        
        # æ˜¾ç¤ºå¤„ç†æ­¥éª¤
        print("\nğŸ“‹ å¤„ç†æ­¥éª¤:")
        for step in result["steps"]:
            print(f"   â€¢ {step['step']}: {step['description']} ({step['time']:.3f}ç§’)")
            if "data" in step and isinstance(step["data"], list):
                for item in step["data"][:2]:  # åªæ˜¾ç¤ºå‰2ä¸ª
                    print(f"     - {item}")
        
        # æ˜¾ç¤ºæœ€ç»ˆç»“æœ
        final_result = result["final_result"]
        if final_result and "ai_response" in final_result:
            print(f"\nğŸ¤– AIå›å¤:")
            response = final_result["ai_response"]
            # æˆªå–å›å¤çš„å‰500å­—ç¬¦
            if len(response) > 500:
                print(f"   {response[:500]}...")
            else:
                print(f"   {response}")
            
            print(f"\nğŸ“Š å¤„ç†ç»Ÿè®¡:")
            print(f"   â€¢ ç›¸å…³æ–°é—»æ•°: {final_result.get('relevant_news_count', 0)}")
            if final_result.get('session_id'):
                print(f"   â€¢ ä¼šè¯ID: {final_result['session_id'][:20]}...")
            print(f"   â€¢ å»ºè®®é—®é¢˜æ•°: {len(final_result.get('suggested_questions', []))}")
            print(f"   â€¢ æ€»å¤„ç†æ—¶é—´: {result['total_time']:.2f}ç§’")
        else:
            print(f"\nâŒ æœªèƒ½ç”Ÿæˆæœ‰æ•ˆå›å¤")
            print(f"   â€¢ æ€»å¤„ç†æ—¶é—´: {result['total_time']:.2f}ç§’")
        
        if i < len(test_scenarios):
            print("\n" + "â”€" * 60)


async def demo_interactive_chat():
    """æ¼”ç¤ºäº¤äº’å¼å¯¹è¯åŠŸèƒ½"""
    await print_banner("äº¤äº’å¼æ–°é—»å¯¹è¯æ¼”ç¤º")
    
    # æ¨¡æ‹Ÿå¤šè½®å¯¹è¯
    chat_session = None
    conversation = [
        "è¯·ä»‹ç»ä¸€ä¸‹æœ€è¿‘çš„AIæŠ€æœ¯å‘å±•",
        "è¿™äº›æŠ€æœ¯çªç ´å¯¹ä¸­å›½æœ‰ä»€ä¹ˆå½±å“ï¼Ÿ",
        "ç›¸æ¯”å…¶ä»–å›½å®¶ï¼Œä¸­å›½çš„ä¼˜åŠ¿åœ¨å“ªé‡Œï¼Ÿ",
        "æœªæ¥å‡ å¹´çš„å‘å±•è¶‹åŠ¿å¦‚ä½•ï¼Ÿ"
    ]
    
    for i, user_input in enumerate(conversation, 1):
        await print_step(i, f"å¯¹è¯è½®æ¬¡ {i}")
        
        print(f"ğŸ‘¤ ç”¨æˆ·: {user_input}")
        
        start_time = time.time()
        chat_result = await rag_pipeline.chat_with_news_context(
            user_input, 
            session_id=chat_session
        )
        chat_time = time.time() - start_time
        
        if "error" in chat_result:
            print(f"âŒ å¯¹è¯å¤±è´¥: {chat_result['error']}")
            break
        
        # æ›´æ–°ä¼šè¯ID
        if not chat_session:
            chat_session = chat_result["session_id"]
            print(f"ğŸ†• åˆ›å»ºæ–°ä¼šè¯: {chat_session[:20]}...")
        
        print(f"ğŸ¤– AIå›å¤: {chat_result['ai_response'][:300]}...")
        print(f"â±ï¸  å›å¤è€—æ—¶: {chat_time:.2f}ç§’")
        
        # æ˜¾ç¤ºç›¸å…³æ–°é—»
        if chat_result["relevant_news"]:
            print(f"ğŸ“° å‚è€ƒæ–°é—»:")
            for news in chat_result["relevant_news"][:2]:
                print(f"   â€¢ {news['title'][:50]}... (ç›¸ä¼¼åº¦: {news['similarity']:.3f})")
        
        if i < len(conversation):
            print()


async def demo_performance_test():
    """æ¼”ç¤ºæ€§èƒ½æµ‹è¯•"""
    await print_banner("æ€§èƒ½æµ‹è¯•æ¼”ç¤º")
    
    print("ğŸ”„ è¿è¡Œæ‰¹é‡æŸ¥è¯¢æ€§èƒ½æµ‹è¯•...")
    
    test_queries = [
        "AIæŠ€æœ¯å‘å±•",
        "æ–°èƒ½æºæ±½è½¦",
        "5Gç½‘ç»œ",
        "é‡å­è®¡ç®—",
        "åŠå¯¼ä½“äº§ä¸š"
    ]
    
    # å¹¶å‘æµ‹è¯•
    concurrent_start = time.time()
    concurrent_tasks = [
        rag_pipeline.search_relevant_news(query, top_k=3) 
        for query in test_queries
    ]
    concurrent_results = await asyncio.gather(*concurrent_tasks)
    concurrent_time = time.time() - concurrent_start
    
    # é¡ºåºæµ‹è¯•
    sequential_start = time.time()
    sequential_results = []
    for query in test_queries:
        result = await rag_pipeline.search_relevant_news(query, top_k=3)
        sequential_results.append(result)
    sequential_time = time.time() - sequential_start
    
    print(f"ğŸ“Š æ€§èƒ½æµ‹è¯•ç»“æœ:")
    print(f"   â€¢ æŸ¥è¯¢æ•°é‡: {len(test_queries)}")
    print(f"   â€¢ å¹¶å‘æ‰§è¡Œæ—¶é—´: {concurrent_time:.3f}ç§’")
    print(f"   â€¢ é¡ºåºæ‰§è¡Œæ—¶é—´: {sequential_time:.3f}ç§’")
    print(f"   â€¢ æ€§èƒ½æå‡: {sequential_time/concurrent_time:.2f}x")
    
    # æ£€æŸ¥ç»“æœä¸€è‡´æ€§
    results_match = all(
        len(concurrent_results[i]) == len(sequential_results[i])
        for i in range(len(test_queries))
    )
    print(f"   â€¢ ç»“æœä¸€è‡´æ€§: {'âœ… é€šè¿‡' if results_match else 'âŒ å¤±è´¥'}")


async def main():
    """ä¸»æ¼”ç¤ºæµç¨‹"""
    print("ğŸš€ å¯åŠ¨Bç«¯RAGæµæ°´çº¿å®Œæ•´æ¼”ç¤º")
    print(f"â° å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    total_start = time.time()
    
    try:
        # 1. æµæ°´çº¿åˆå§‹åŒ–
        await demo_pipeline_initialization()
        
        # 2. æ–°é—»æ£€ç´¢æ¼”ç¤º
        await demo_news_search()
        
        # 3. å®Œæ•´æµæ°´çº¿æ¼”ç¤º
        await demo_complete_pipeline()
        
        # 4. äº¤äº’å¼å¯¹è¯æ¼”ç¤º
        await demo_interactive_chat()
        
        # 5. æ€§èƒ½æµ‹è¯•
        await demo_performance_test()
        
        total_time = time.time() - total_start
        
        await print_banner("æ¼”ç¤ºå®Œæˆ")
        print(f"ğŸ‰ æ‰€æœ‰æ¼”ç¤ºå·²å®Œæˆï¼")
        print(f"â±ï¸  æ€»è€—æ—¶: {total_time:.2f}ç§’")
        print(f"ğŸ“Š æ¼”ç¤ºç»Ÿè®¡:")
        
        status = await rag_pipeline.get_pipeline_status()
        print(f"   â€¢ å¤„ç†æ–°é—»æ€»æ•°: {status['total_news']}")
        print(f"   â€¢ å‘é‡å­˜å‚¨å¤§å°: {status['vector_store_size']}")
        print(f"   â€¢ æ”¯æŒçš„æœåŠ¡: {', '.join(status['services_status'].keys())}")
        
        print("\nâœ… Bç«¯RAGæµæ°´çº¿åŠŸèƒ½éªŒè¯å®Œæˆ!")
        print("ğŸ“ ç³»ç»Ÿèƒ½å¤ŸæˆåŠŸå®Œæˆ:")
        print("   â€¢ æ–°é—»æ•°æ®embeddingç”Ÿæˆ")
        print("   â€¢ å‘é‡ç›¸ä¼¼åº¦æ£€ç´¢")
        print("   â€¢ RAGå¢å¼ºçš„æ–°é—»å¡ç‰‡ç”Ÿæˆ") 
        print("   â€¢ åŸºäºæ–°é—»ä¸Šä¸‹æ–‡çš„æ™ºèƒ½å¯¹è¯")
        print("   â€¢ å¤šè½®å¯¹è¯ä¸Šä¸‹æ–‡ç®¡ç†")
        
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        print(f"\nğŸ æ¼”ç¤ºç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")


if __name__ == "__main__":
    asyncio.run(main()) 