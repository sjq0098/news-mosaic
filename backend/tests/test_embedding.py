"""
Embedding æœåŠ¡æµ‹è¯•
"""

import asyncio
import sys
import os
# å°† backend ç›®å½•æ”¾åˆ° sys.path é¦–ä½ï¼Œç¡®ä¿ä¼˜å…ˆä½¿ç”¨æœ¬åœ° services åŒ…
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from services.embedding_service import embedding_service



async def test_embedding_service():
    """æµ‹è¯• embedding æœåŠ¡"""
    
    # æµ‹è¯•æ–‡æœ¬
    test_text = """
    äººå·¥æ™ºèƒ½ï¼ˆArtificial Intelligenceï¼ŒAIï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œ
    å®ƒä¼å›¾äº†è§£æ™ºèƒ½çš„å®è´¨ï¼Œå¹¶ç”Ÿäº§å‡ºä¸€ç§æ–°çš„èƒ½ä»¥äººç±»æ™ºèƒ½ç›¸ä¼¼çš„æ–¹å¼åšå‡ºååº”çš„æ™ºèƒ½æœºå™¨ã€‚
    è¯¥é¢†åŸŸçš„ç ”ç©¶åŒ…æ‹¬æœºå™¨äººã€è¯­è¨€è¯†åˆ«ã€å›¾åƒè¯†åˆ«ã€è‡ªç„¶è¯­è¨€å¤„ç†å’Œä¸“å®¶ç³»ç»Ÿç­‰ã€‚
    
    æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ï¼Œå®ƒæ˜¯ä¸€ç§è®©è®¡ç®—æœºç³»ç»Ÿè‡ªåŠ¨å­¦ä¹ å’Œæ”¹è¿›çš„æ–¹æ³•ï¼Œ
    æ— éœ€è¢«æ˜ç¡®ç¼–ç¨‹ã€‚æœºå™¨å­¦ä¹ ç®—æ³•é€šè¿‡åˆ†æå¤§é‡æ•°æ®æ¥è¯†åˆ«æ¨¡å¼ï¼Œå¹¶ä½¿ç”¨è¿™äº›æ¨¡å¼æ¥åšå‡ºé¢„æµ‹æˆ–å†³ç­–ã€‚
    
    æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é›†ï¼Œå®ƒä½¿ç”¨äººå·¥ç¥ç»ç½‘ç»œæ¥æ¨¡æ‹Ÿäººè„‘çš„å·¥ä½œæ–¹å¼ã€‚
    æ·±åº¦å­¦ä¹ åœ¨å›¾åƒè¯†åˆ«ã€è¯­éŸ³è¯†åˆ«ã€è‡ªç„¶è¯­è¨€å¤„ç†ç­‰é¢†åŸŸå–å¾—äº†æ˜¾è‘—çš„æˆæœã€‚
    """
    
    # æµ‹è¯•å…ƒæ•°æ®
    metadata = {
        "title": "äººå·¥æ™ºèƒ½ä»‹ç»",
        "category": "technology",
        "author": "æµ‹è¯•ä½œè€…",
        "published_at": "2024-01-01T00:00:00Z"
    }
    
    try:
        print("ğŸ”„ å¼€å§‹æµ‹è¯• embedding æœåŠ¡...")
        
        # 1. æµ‹è¯•æ–‡æœ¬åˆ†å—
        print("\nğŸ“ æµ‹è¯•æ–‡æœ¬åˆ†å—...")
        chunks = await embedding_service.chunk_text(test_text, metadata)
        print(f"åˆ†å—æ•°é‡: {len(chunks)}")
        for i, chunk in enumerate(chunks):
            print(f"åˆ†å— {i}: {chunk.token_count} tokens, é•¿åº¦: {len(chunk.content)} å­—ç¬¦")
            print(f"å†…å®¹é¢„è§ˆ: {chunk.content[:100]}...")
        
        # 2. æµ‹è¯•å®Œæ•´å¤„ç†
        print("\nğŸš€ æµ‹è¯•å®Œæ•´å¤„ç†...")
        results = await embedding_service.process_text(
            text=test_text,
            source_id="test_001",
            metadata=metadata
        )
        
        print(f"å¤„ç†ç»“æœ: {len(results)} ä¸ªå‘é‡")
        for i, result in enumerate(results):
            print(f"å‘é‡ {i}: ç»´åº¦ {len(result.embedding)}, å¤„ç†æ—¶é—´: {result.processing_time:.3f}s")
        
        # 3. æµ‹è¯•æ‰¹é‡å¤„ç†
        print("\nâš¡ æµ‹è¯•æ‰¹é‡å¤„ç†...")
        batch_results = await embedding_service.process_texts_batch(
            texts=[test_text, "è¿™æ˜¯ç¬¬äºŒä¸ªæµ‹è¯•æ–‡æœ¬ã€‚"],
            source_ids=["test_001", "test_002"],
            metadatas=[metadata, {"title": "æµ‹è¯•æ–‡æœ¬2"}]
        )
        
        print(f"æ‰¹é‡å¤„ç†ç»“æœ: {len(batch_results)} ä¸ªæ–‡æœ¬")
        for i, text_results in enumerate(batch_results):
            print(f"æ–‡æœ¬ {i}: {len(text_results)} ä¸ªå‘é‡")
        
        # 4. è·å–æ¨¡å‹ä¿¡æ¯
        print("\nğŸ“Š æ¨¡å‹ä¿¡æ¯:")
        model_info = await embedding_service.get_model_info()
        for key, value in model_info.items():
            print(f"  {key}: {value}")
        
        print("\nâœ… æµ‹è¯•å®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        raise
    finally:
        await embedding_service.close()


if __name__ == "__main__":
    asyncio.run(test_embedding_service())
